# Grabadora Pro

Plataforma moderna para transcribir audios con WhisperX, identificar hablantes, guardar resultados en una base de datos consultable y ofrecer una interfaz web lista para desplegar en Docker.

## Caracter√≠sticas principales

- **API FastAPI** con endpoints para subir audios en lote, consultar, descargar y eliminar transcripciones.
- **Integraci√≥n con WhisperX** para transcripci√≥n r√°pida y diarizaci√≥n de hablantes: prioriza GPU/CUDA cuando est√° disponible y cae autom√°ticamente a CPU o al transcriptor simulado en entornos sin aceleraci√≥n.
- **Base de datos SQLite / SQLAlchemy** con b√∫squeda por texto, asignatura y estado.
- **Generaci√≥n autom√°tica de archivos `.txt`** y estructura extensible para futuros planes premium con IA externa.
- **Interfaz web** en `/` con selector multimedia animado, validaci√≥n de audio/video y barra de progreso en tiempo real.
- **Dashboard con m√©tricas en vivo** (totales, completadas, minutos procesados, etc.) y vista estilo ChatGPT con animaci√≥n adaptativa que escribe seg√∫n el modelo y el dispositivo usado, desplazando la vista autom√°ticamente.
- **Beneficios premium simulados** con checkout y confirmaci√≥n que desbloquean notas IA enriquecidas sin mostrar importes hasta definir tu estrategia comercial.
- **Selector de idioma** con espa√±ol (predeterminado), ingl√©s y franc√©s, adem√°s de autodetecci√≥n cuando lo necesites.
- **Modo estudiante web**: vista ligera con anuncios educativos y ejecuci√≥n local accesible en `student.html` o desde el bot√≥n ‚ÄúAbrir simulador independiente‚Äù.
- **Inicio de sesi√≥n con Google (OAuth 2.0)** listo para conectar con tus credenciales y personalizar la experiencia del dashboard.
- **Dockerfile y docker-compose** para ejecutar el servicio completo (API + frontend) y posibilidad de habilitar GPU.
- **Tests con Pytest** que validan el flujo principal usando un transcriptor simulado y comprueban la compatibilidad con las versiones recientes de faster-whisper.

## Requisitos

- Python 3.10 o superior.
- FFmpeg disponible en la ruta (`apt install ffmpeg` o equivalente).
- Dependencias de base de datos incluidas (por ejemplo, `aiosqlite` para el driver as√≠ncrono de SQLite).
- Librer√≠as auxiliares para la interfaz (`aiofiles` para servir los archivos est√°ticos).
- Para usar WhisperX real: `torch` compatible y opcionalmente GPU con CUDA.

## Instalaci√≥n local

### Crear entorno virtual

```bash
python -m venv .venv
```

- **Linux / macOS:** `source .venv/bin/activate`
- **Windows (PowerShell):** `.\.venv\Scripts\Activate.ps1`
- **Windows (CMD):** `.\.venv\Scripts\activate.bat`

> **Importante (Windows):** si ves advertencias indicando que `pip.exe` o `uvicorn.exe` no est√°n en el PATH, a√∫n no se ha
> activado el entorno virtual. Act√≠valo y utiliza siempre `python -m pip` para asegurarte de instalar en la misma versi√≥n de
> Python con la que ejecutar√°s la aplicaci√≥n.

### Instalar dependencias y preparar la base de datos

```bash
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
python -m scripts.init_db
```

Para comprobar que todo est√° listo puedes ejecutar:

```bash
python -m scripts.doctor
```

El comando revisa las dependencias clave (FastAPI, SQLAlchemy, WhisperX, etc.) y muestra c√≥mo resolver cualquier ausencia.

### Copiar y pegar todo el flujo

#### Windows (PowerShell)

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
python -m scripts.init_db
python -m scripts.doctor
python -m uvicorn app.main:app --reload
```

### Consejos para merges sin dolor

Si resuelves a menudo los mismos conflictos en GitHub, puedes pedirle a Git que
recuerde tus decisiones con `rerere` (reuse recorded resolution). Act√≠valo una
sola vez en tu m√°quina y Git repetir√° autom√°ticamente las resoluciones que ya
conocen:

```bash
git config --global rerere.enabled true
git config --global rerere.autoUpdate true
```

Cuando aparezca un conflicto nuevo, resu√©lvelo como siempre, ejecuta `git add`
para marcarlo como solucionado y finaliza el merge/rebase. La pr√≥xima vez que
surja la misma colisi√≥n Git propondr√° tu soluci√≥n sin que tengas que revisar el
archivo manualmente.

#### Linux / macOS

```bash
python -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
python -m scripts.init_db
python -m scripts.doctor
python -m uvicorn app.main:app --reload
```

### Arrancar la API en modo desarrollo

```bash
python -m uvicorn app.main:app --reload
```

La interfaz quedar√° disponible en http://127.0.0.1:8000/ y la API en http://127.0.0.1:8000/api/transcriptions.

### Variables de entorno √∫tiles

| Variable | Descripci√≥n | Valor por defecto |
| --- | --- | --- |
| `DATABASE_URL` | Cadena de conexi√≥n async SQLAlchemy | `sqlite+aiosqlite:///./data/app.db` |
| `SYNC_DATABASE_URL` | Cadena de conexi√≥n s√≠ncrona | `sqlite:///./data/app.db` |
| `STORAGE_DIR` | Carpeta donde se guardan audios | `data/uploads` |
| `TRANSCRIPTS_DIR` | Carpeta de archivos `.txt` | `data/transcripts` |
| `WHISPER_MODEL_SIZE` | Modelo WhisperX a usar | `large-v3` |
| `WHISPER_DEVICE` | `cuda` o `cpu` | `cuda` |
| `WHISPER_FORCE_CUDA` | Fuerza el uso de CUDA (no cae a CPU si falla) | `false` |
| `ENABLE_DUMMY_TRANSCRIBER` | Usa transcriptor simulado (ideal para pruebas) | `false` |
| `HUGGINGFACE_TOKEN` | Token opcional para descargar el VAD de `pyannote/segmentation` | *(vac√≠o)* |

## Uso de la API

- `POST /api/transcriptions`: Subir un audio (`multipart/form-data`) con campos opcionales `language`, `subject`, `model_size` y `device_preference`.
- `POST /api/transcriptions/batch`: Subida m√∫ltiple (`uploads[]`) aplicando la misma configuraci√≥n a todos los archivos.
- `GET /api/transcriptions`: Listar y buscar transcripciones (`q`, `status`, `premium_only`).
- `GET /api/transcriptions/{id}`: Detalle con segmentos y hablantes.
- `GET /api/transcriptions/{id}/download`: Descarga del `.txt` generado.
- `DELETE /api/transcriptions/{id}`: Eliminaci√≥n.
- `GET /api/transcriptions/health`: Comprobaci√≥n r√°pida del servicio.
- `GET /api/payments/plans`: Listado de planes activos.
- `POST /api/payments/checkout`: Crea un checkout para un plan y una transcripci√≥n concreta.
- `POST /api/payments/{id}/confirm`: Marca la compra como completada y desbloquea las notas premium.

## Modo estudiante en la web

- Desde el panel principal pulsa **‚ÄúAbrir simulador independiente‚Äù** para lanzar `student.html` en una nueva pesta√±a.
- La versi√≥n educativa sincroniza el texto con el backend cada pocos segundos, escribe con animaciones m√°s pausadas y muestra
  anuncios discretos entre segmentos.
- Tambi√©n puedes acceder directamente navegando a `http://localhost:8000/student.html` cuando el servidor est√© activo.

## Benchmarks desde tu base de datos

Utiliza el script `scripts/benchmark_models.py` para comparar la duraci√≥n real de tus transcripciones frente al tiempo de
ejecuci√≥n observado. Ejemplos:

```bash
python -m scripts.benchmark_models --models large-v2 large-v3
python -m scripts.benchmark_models --subject historia --export metrics.json
```

El resultado imprime una tabla con n√∫mero de muestras, duraci√≥n media, runtime medio y caracteres/segundo para documentar la
mejora obtenida al cambiar de modelo.

## ¬øProblemas descargando el VAD de HuggingFace?

Si ves errores `401` o `403` al intentar descargar `pyannote/segmentation`, configura la variable de entorno
`HUGGINGFACE_TOKEN` con tu token personal (`huggingface-cli login`). Cuando no haya token, la aplicaci√≥n reduce el log a una
advertencia y contin√∫a con el fallback de faster-whisper para evitar bloqueos.

## Docker

### Construir y ejecutar (CPU)

```bash
docker compose up --build
```

El servicio quedar√° expuesto en http://localhost:8000.

### Ejecutar con GPU

1. Instala [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).
2. Ajusta `docker-compose.gpu.yml` o ejecuta:

```bash
docker compose -f docker-compose.yml --profile gpu up --build
```

> El contenedor ya incluye WhisperX; instala `torch` con soporte CUDA si tu GPU lo requiere.

## Pruebas

```bash
pytest
```

Las pruebas activan el transcriptor simulado para validar el ciclo completo sin depender de WhisperX real e incluyen el flujo de pagos premium.

## Contenido premium y notas IA

Al confirmar una compra, la API genera notas premium autom√°ticamente (`app/utils/notes.py`). El motor actual resume, destaca ideas y propone pr√≥ximos pasos de manera heur√≠stica, listo para que sustituyas la l√≥gica por tu integraci√≥n favorita (OpenAI, Azure, etc.) cuando habilites cobros reales.

## Estructura de carpetas

```
app/
  config.py
  database.py
  main.py
  models.py
  routers/
    transcriptions.py
    payments.py
  schemas.py
  utils/
    storage.py
    payments.py
    notes.py
  whisper_service.py
frontend/
  index.html
  styles.css
  app.js
scripts/
  init_db.py
tests/
  test_api.py
```

## Contribuciones

1. Crea una rama descriptiva.
2. A√±ade tests para nuevas funcionalidades.
3. Ejecuta `pytest` antes de enviar tu PR.

¬°Felices transcripciones! üéôÔ∏è
